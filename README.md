# Assessment 2
Prerequisits: Jyputer notebook, latest version of Apache Spark, Pyspark libraries

In this project, you will understand a few basic Python operations on a dataframe.

Download a sample JSON file, containing the reviews and ratings of a few locations.

Operations demonstrated in the code file:

1. Loading the file to the Jyputer notebook using the spark.read operation and convert it to a dataframe. The CreateOrReplaceTempView()()unction creates a table name that can be used in spark-sql queries.

2. A spark-sql query to convert the epoch time to date string with mm-dd-yyyy format

3. Create a table in postgre to load the dataframe. Use the following code to write the data to postgre server

4. Writing the dataframe to parquet file

<img width="1512" alt="Screenshot 2024-02-08 at 1 34 33 AM" src="https://github.com/vishalav95/Pyspark_Assessment_2/assets/35730889/11761793-cb18-4fd7-8097-0df5306db696">
<img width="778" alt="Screenshot 2024-02-08 at 1 34 43 AM" src="https://github.com/vishalav95/Pyspark_Assessment_2/assets/35730889/f00a5b39-041d-4a12-8b72-93a91e43c64f">
<img width="717" alt="Screenshot 2024-02-08 at 1 35 12 AM" src="https://github.com/vishalav95/Pyspark_Assessment_2/assets/35730889/40126a19-b483-4ec4-8619-9704f0d97a77">
